{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtNelyWy13GBQ7TL3CP4CD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauravakriti/gauravakriti/blob/main/NLP_day1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LDyPnhK63bIE"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ripK6vpbAnJE",
        "outputId": "d7bcfc54-c873-4926-cd30-05dc63742172"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_sentence(sentence):\n",
        "    print(word_tokenize(sentence))\n",
        "\n",
        "sentence = \"This is a sample sentence for tokenization.\"\n",
        "tokenize_sentence(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV9aqSmL_0si",
        "outputId": "b49ab68b-2c67-44b0-a279-41fa6423d1a2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'is', 'a', 'sample', 'sentence', 'for', 'tokenization', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tockenize_sent(sent):\n",
        "    print(sent_tokenize(sent))\n",
        "\n",
        "sent = \"Once upon a time in a lush green valley nestled between towering mountains, there lived a curious little fox named Felix. Felix was unlike any other fox in the valley; he was known for his insatiable thirst for adventure and his boundless curiosity about the world beyond the valley.Every day, Felix would explore the nooks and crannies of the valley, discovering hidden trails, secret meadows, and sparkling streams. But deep down, he yearned for something more—a grand adventure that would take him far beyond the familiar sights of his home.One sunny morning, as Felix was frolicking in the meadow, he spotted a mysterious old map fluttering in the breeze. Intrigued, he pounced on the map and examined it closely. The map depicted a distant land filled with towering forests, shimmering lakes, and majestic mountains—a land ripe with untold treasures and ancient mysteries.\"\n",
        "tockenize_sent(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yPM7iz3Afi3",
        "outputId": "101e600e-47ff-4a0a-b009-4095eb75d8cc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once upon a time in a lush green valley nestled between towering mountains, there lived a curious little fox named Felix.', 'Felix was unlike any other fox in the valley; he was known for his insatiable thirst for adventure and his boundless curiosity about the world beyond the valley.Every day, Felix would explore the nooks and crannies of the valley, discovering hidden trails, secret meadows, and sparkling streams.', 'But deep down, he yearned for something more—a grand adventure that would take him far beyond the familiar sights of his home.One sunny morning, as Felix was frolicking in the meadow, he spotted a mysterious old map fluttering in the breeze.', 'Intrigued, he pounced on the map and examined it closely.', 'The map depicted a distant land filled with towering forests, shimmering lakes, and majestic mountains—a land ripe with untold treasures and ancient mysteries.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def remove_stopwords(sentence):\n",
        "    import nltk\n",
        "    nltk.download('stopwords')\n",
        "    words = word_tokenize(sentence)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "    filtered_sentence = ' '.join(filtered_words)\n",
        "    print(\"Sentence without stopwords:\", filtered_sentence)\n",
        "\n",
        "sentence = \"Once upon a time in a lush green valley nestled between towering mountains, there lived a curious little fox named Felix. Felix was unlike any other fox in the valley; he was known for his insatiable thirst for adventure and his boundless curiosity about the world beyond the valley.Every day, Felix would explore the nooks and crannies of the valley, discovering hidden trails, secret meadows, and sparkling streams. But deep down, he yearned for something more—a grand adventure that would take him far beyond the familiar sights of his home.One sunny morning, as Felix was frolicking in the meadow, he spotted a mysterious old map fluttering in the breeze. Intrigued, he pounced on the map and examined it closely. The map depicted a distant land filled with towering forests, shimmering lakes, and majestic mountains—a land ripe with untold treasures and ancient mysteries.\"\n",
        "remove_stopwords(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoBO0zaDC5uM",
        "outputId": "bdba1a2b-d7e7-4a24-d45d-1c85b2b33d4d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence without stopwords: upon time lush green valley nestled towering mountains , lived curious little fox named Felix . Felix unlike fox valley ; known insatiable thirst adventure boundless curiosity world beyond valley.Every day , Felix would explore nooks crannies valley , discovering hidden trails , secret meadows , sparkling streams . deep , yearned something more—a grand adventure would take far beyond familiar sights home.One sunny morning , Felix frolicking meadow , spotted mysterious old map fluttering breeze . Intrigued , pounced map examined closely . map depicted distant land filled towering forests , shimmering lakes , majestic mountains—a land ripe untold treasures ancient mysteries .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import FreqDist\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def calculate_word_frequency(text):\n",
        "    words = word_tokenize(text)\n",
        "    freq_dist = FreqDist(words)\n",
        "    print(\"Top 5 most common words:\")\n",
        "    for word, frequency in freq_dist.most_common(5):\n",
        "        print(f\"{word}: {frequency}\")\n",
        "\n",
        "\n",
        "text = \"This is a sample text. It contains some sample words for demonstration purposes.\"\n",
        "calculate_word_frequency(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOSFzyJXEIF5",
        "outputId": "33e00c25-d3b9-44d8-8bf0-c7cb5842aac7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 most common words:\n",
            "sample: 2\n",
            ".: 2\n",
            "This: 1\n",
            "is: 1\n",
            "a: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHXlXBhdjI8g"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qaXq-51Ql5J3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "zOJIQ_arklVA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "words= [\"writing\", \"Clicking\",\"doing\",\"reading\", \"ready \", \"writes\"]\n",
        "#sample_ps =PorterStemmer()\n",
        "for x in words:\n",
        "    root_Word=PorterStemmer().stem(x)\n",
        "    print(root_Word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJhFNvUdkv0a",
        "outputId": "3faa910e-87e0-4464-a87c-cd855c839175"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write\n",
            "click\n",
            "do\n",
            "read\n",
            "ready \n",
            "write\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import \tWordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "text = \"writes dancing study studying\"\n",
        "tokenization = nltk.word_tokenize(text)\n",
        "for w in tokenization:\n",
        "    print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ux5ozX93l6LT",
        "outputId": "e4991878-1b41-4b59-ee58-5e249b1d4325"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemma for writes is writes\n",
            "Lemma for dancing is dancing\n",
            "Lemma for study is study\n",
            "Lemma for studying is studying\n"
          ]
        }
      ]
    }
  ]
}